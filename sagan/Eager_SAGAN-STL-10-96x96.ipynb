{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative_Adversarial_Nets_Eager.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sthalles/blog-resources/blob/master/sagan/Eager_SAGAN-STL-10-96x96.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Daz4EN2qNu27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "919f1729-966c-4481-c6f2-71a6b3f24bc9"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "tf.enable_eager_execution()\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0-rc2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZDlOUlqtvVO3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "5b6522a6-6ada-4690-e9a0-617c63587f81"
      },
      "cell_type": "code",
      "source": [
        "# To install Kaggle CLI\n",
        "!pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.3.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.23.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.4.16)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RvkuOPAYulQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d8478e1-3e8d-4118-afc9-9e0fbf84c54b"
      },
      "cell_type": "code",
      "source": [
        "# Import kaggle.json from google drive\n",
        "# This snippet will output a link which needs authentication from any google account\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "    q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "# print(kaggle_api_key)\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YGEY1cvCvSI-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "744039ef-5ab8-43a6-fb29-ea98ba29321a"
      },
      "cell_type": "code",
      "source": [
        "# Use this command in new cell\n",
        "#!kaggle datasets download -d assignment-2-stl-10 -w -f unlabeled_images.zip\n",
        "\n",
        "!kaggle datasets download -d jessicali9530/stl10 -w -f unlabeled_images.zip\n",
        "\n",
        "# Unzip the data\n",
        "!unzip unlabeled_images.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unlabeled_images.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  unlabeled_images.zip\n",
            "replace unlabeled_image_png_61181.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "43Kz49FTucxn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = read_all_images(\"./data/stl10_binary/train_X.bin\")\n",
        "print(\"Train data shape:\", X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2paiYCUGODZQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cifar_10 = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "n_classes = len(cifar_10)\n",
        "print(\"Number of classes:\", n_classes)\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(18,8))\n",
        "n_columns = 8\n",
        "n_rows = 4\n",
        "\n",
        "for i in range(1,n_columns*n_rows+1):\n",
        "  fig.add_subplot(n_rows, n_columns, i)\n",
        "  plt.imshow(X_train[i])\n",
        "  # plt.title(cifar_10[y_train[i]])\n",
        "  # Turn off tick labels\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ymSP1wKj9N0E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfe = tf.contrib.eager"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AepL7NbSdcFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # simulate conv filter\n",
        "# w = tfe.Variable(tf.truncated_normal(shape=[3, 3, 16, 32])) # (3, 3, 16, 32)\n",
        "# print(\"w:\", w.shape)\n",
        "\n",
        "# u = tfe.Variable(tf.truncated_normal(shape=[1,w.shape[-1]])) # (1, 32)\n",
        "# print(\"u:\", u.shape)\n",
        "\n",
        "# w_reshape = tf.reshape(w, (-1, w.shape[-1])) # (144, 32)\n",
        "# print(\"w_reshape:\", w_reshape.shape)\n",
        "\n",
        "# wu = tf.matmul(u, tf.transpose(w_reshape)) # (1, 144)\n",
        "# print(\"wu:\", wu.shape)\n",
        "# v = wu / tf.nn.l2_normalize(wu)\n",
        "# print(\"v:\", v.shape)\n",
        "\n",
        "# wv = tf.matmul(v, w_reshape)\n",
        "# u = wv / tf.nn.l2_normalize(wv)\n",
        "# print(\"u:\", u.shape)\n",
        "\n",
        "# # Calculate WSN with the spectral norm\n",
        "# sigma = tf.matmul(tf.matmul(v, w_reshape), tf.transpose(u))\n",
        "# WSN = w_reshape / sigma\n",
        "# print(\"WSN:\", WSN.shape)\n",
        "\n",
        "# WSN = tf.reshape(WSN, w.shape)\n",
        "# print(\"WSN:\", WSN.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Ck_G_m7XczB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SelfAttention(tf.keras.Model):\n",
        "  def __init__(self, number_of_filters):\n",
        "    super(SelfAttention, self).__init__(number_of_filters)\n",
        "    \n",
        "    self.f = tf.keras.layers.Conv2D(number_of_filters//8, 1, \n",
        "                                     strides=1, padding='SAME', \n",
        "                                     activation=None)\n",
        "    \n",
        "    self.g = tf.keras.layers.Conv2D(number_of_filters//8, 1, \n",
        "                                     strides=1, padding='SAME', \n",
        "                                     activation=None)\n",
        "    \n",
        "    self.h = tf.keras.layers.Conv2D(number_of_filters, 1, \n",
        "                                     strides=1, padding='SAME', \n",
        "                                     activation=None)\n",
        "    \n",
        "    self.gamma = tfe.Variable(0.0, trainable=True, dtype=tf.float32) \n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    \n",
        "  def call(self, x):\n",
        "    input_shape = tf.shape(x)\n",
        "    f = self.f(x)\n",
        "    g = self.g(x)\n",
        "    h = self.h(x)\n",
        "    \n",
        "    f_flatten = self.flatten(f)\n",
        "    g_flatten = self.flatten(g)\n",
        "    h_flatten = self.flatten(h)\n",
        "    \n",
        "    s = tf.matmul(g_flatten, f_flatten, transpose_b=True)\n",
        "    B = tf.nn.softmax(s)\n",
        "\n",
        "    o = tf.matmul(B, h_flatten)\n",
        "    \n",
        "    y = self.gamma * o + self.flatten(x)\n",
        "    return tf.reshape(y, input_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XhTsJYykucyA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://github.com/sthalles/blog-resources/blob/master/sagan/images/sngan_network_architecture.png?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "g52OgUeWYU6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z_size = 128\n",
        "learning_rate_generator = 0.0001\n",
        "learning_rate_discriminator = 0.0004\n",
        "batch_size = 100\n",
        "alpha = 0.1\n",
        "beta1 = 0.0\n",
        "beta2 = 0.9\n",
        "bn_momentum = 0.1\n",
        "bn_epsilon  = 0.00002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XuZRiqoiucyH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from libs.conv_spectral_norm import Conv2D, Conv2DTranspose"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AuqiX32cONPo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    # define the generator's layers\n",
        "    \n",
        "    self.fc1 = tf.keras.layers.Dense(units=6*6*512, activation=\"relu\")\n",
        "\n",
        "    self.transp_conv1 = Conv2DTranspose(256, 4, spectral_normalization=True, strides=2, padding=\"SAME\", activation=None)\n",
        "    \n",
        "    # BN + ReLU\n",
        "    self.bn1 = tf.keras.layers.BatchNormalization(scale=False, epsilon=bn_epsilon, momentum=bn_momentum)\n",
        "    self.activation1 = tf.keras.layers.Activation(activation='relu')\n",
        "    \n",
        "    self.transp_conv2 = Conv2DTranspose(128, 4, spectral_normalization=True, strides=2, padding=\"SAME\", activation=None)\n",
        "    \n",
        "    # BN + ReLU\n",
        "    self.bn2 = tf.keras.layers.BatchNormalization(scale=False, epsilon=bn_epsilon, momentum=bn_momentum)\n",
        "    self.activation2 = tf.keras.layers.Activation(activation='relu')\n",
        "    \n",
        "    self.transp_conv3 = Conv2DTranspose(64, 4, spectral_normalization=True, strides=2, padding=\"SAME\", activation=None)\n",
        "    \n",
        "    self.bn3 = tf.keras.layers.BatchNormalization(scale=False, epsilon=bn_epsilon, momentum=bn_momentum)\n",
        "    self.activation3 = tf.keras.layers.Activation(activation='relu')\n",
        "    \n",
        "    # pass the number of filters of the current feature volume\n",
        "    self.attention = SelfAttention(64)\n",
        "\n",
        "    self.transp_conv4 = Conv2DTranspose(32, 4, spectral_normalization=True, strides=2, padding=\"SAME\", activation=None)\n",
        "    \n",
        "    self.bn4 = tf.keras.layers.BatchNormalization(scale=False, epsilon=bn_epsilon, momentum=bn_momentum)\n",
        "    self.activation4 = tf.keras.layers.Activation(activation='relu')\n",
        "    \n",
        "    self.conv = Conv2D(3, 3, strides=1, spectral_normalization=True, padding='SAME', activation=None)\n",
        "    self.out = tf.keras.layers.Activation(activation='tanh')\n",
        "    \n",
        "  def call(self, z, is_training):\n",
        "\n",
        "    fc1 = self.fc1(z)\n",
        "    fc1_reshaped = tf.reshape(fc1, (-1,6,6,512))\n",
        "\n",
        "    trans_conv1 = self.transp_conv1(fc1_reshaped, training=is_training)\n",
        "    bn1 = self.bn1(trans_conv1, training=is_training)\n",
        "    activation1 = self.activation1(bn1)\n",
        "\n",
        "    transp_conv2 = self.transp_conv2(activation1, training=is_training)\n",
        "    bn2 = self.bn2(transp_conv2, training=is_training)\n",
        "    activation2 = self.activation2(bn2)\n",
        "    \n",
        "    transp_conv3 = self.transp_conv3(activation2, training=is_training)\n",
        "    bn3 = self.bn3(transp_conv3, training=is_training)\n",
        "    activation3 = self.activation3(bn3)\n",
        "    \n",
        "    attention = self.attention(activation3)\n",
        "    \n",
        "    transp_conv4 = self.transp_conv3(attention, training=is_training)\n",
        "    bn4 = self.bn3(transp_conv4, training=is_training)\n",
        "    activation4 = self.activation3(bn4)\n",
        "    \n",
        "    conv = self.conv(activation4, training=is_training)\n",
        "    output = self.out(conv)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vhqWL2DTZSPO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "  def __init__(self, alpha):\n",
        "    super(Discriminator, self).__init__()\n",
        "    \n",
        "    # -------- Block 1\n",
        "    self.conv1 = Conv2D(32, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
        "    self.activation1 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
        "  \n",
        "    self.conv2 = Conv2D(32, 4, spectral_normalization=True, strides=2, padding='SAME', activation=None)\n",
        "    self.activation2 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
        "    \n",
        "    # pass the number of filters of the current feature volume\n",
        "    self.attention = SelfAttention(32)\n",
        "    \n",
        "    # -------- Block 2\n",
        "    self.conv3 = Conv2D(64, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
        "    self.activation3 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
        "    \n",
        "    self.conv4 = Conv2D(64, 4, spectral_normalization=True, strides=2, padding='SAME', activation=None)\n",
        "    self.activation4 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
        "    \n",
        "    # -------- Block 3\n",
        "    self.conv5 = Conv2D(128, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
        "    self.activation5 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
        "    \n",
        "    self.conv6 = Conv2D(128, 4, spectral_normalization=True, strides=2, padding='SAME', activation=None)\n",
        "    self.activation6 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
        "    \n",
        "    # -------- Block 4\n",
        "    self.conv7 = Conv2D(256, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
        "    self.activation7 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
        "    \n",
        "    self.conv8 = Conv2D(256, 4, spectral_normalization=True, strides=2, padding='SAME', activation=None)\n",
        "    self.activation8 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
        "    # --------\n",
        "    \n",
        "    self.conv9 = Conv2D(512, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
        "    self.activation9 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
        "    \n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.fc1 = tf.keras.layers.Dense(units=1, activation=None)\n",
        "    \n",
        "  \n",
        "  def call(self, inputs, is_training):\n",
        "\n",
        "    conv1 = self.conv1(inputs, training=is_training)\n",
        "    activation1 = self.activation1(conv1)\n",
        "        \n",
        "    conv2 = self.conv2(activation1, training=is_training)\n",
        "    activation2 = self.activation2(conv2)\n",
        "    \n",
        "    attention = self.attention(activation2)\n",
        "\n",
        "    conv3 = self.conv3(attention, training=is_training)\n",
        "    activation3 = self.activation3(conv3)\n",
        "    \n",
        "    conv4 = self.conv4(activation3, training=is_training)\n",
        "    activation4 = self.activation4(conv4)\n",
        "    \n",
        "    conv5 = self.conv5(activation4, training=is_training)\n",
        "    activation5 = self.activation5(conv5)\n",
        "    \n",
        "    conv6 = self.conv6(activation5, training=is_training)\n",
        "    activation6 = self.activation6(conv6)\n",
        "    \n",
        "    conv7 = self.conv7(activation6, training=is_training)\n",
        "    activation7 = self.activation7(conv7)\n",
        "    \n",
        "    conv8 = self.conv8(activation7, training=is_training)\n",
        "    activation8 = self.activation8(conv8)\n",
        "    \n",
        "    conv9 = self.conv9(activation8, training=is_training)\n",
        "    activation9 = self.activation9(conv8)\n",
        "    \n",
        "    flat = self.flatten(activation9)\n",
        "    logits = self.fc1(flat)\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ehm_VlwuVLGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator_net = Generator()\n",
        "discriminator_net = Discriminator(alpha=alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QveA21KOB4XM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator_loss(d_logits_fake):\n",
        "  return - tf.reduce_mean(d_logits_fake)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1BenLQsgCvnR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator_loss(d_logits_real, d_logits_fake):\n",
        "  return tf.reduce_mean(- tf.minimum(0, -1. + d_logits_real)) - tf.reduce_mean(tf.minimum(0, -1. - d_logits_fake))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11WPYNiD1Tdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logdir = \"./model/logs/\"\n",
        "tf_board_writer = tf.contrib.summary.create_file_writer(logdir)\n",
        "tf_board_writer.set_as_default()\n",
        "\n",
        "global_counter = tf.train.get_or_create_global_step()\n",
        "generator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_generator, beta1=beta1, beta2=beta2)\n",
        "discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_discriminator, beta1=beta1, beta2=beta2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HK3WmI7iucyw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"./model\"\n",
        "generator_checkpoint_prefix = os.path.join(checkpoint_dir, \"generator_checkpoints\", \"generator.ckpt\")\n",
        "gen_root = tfe.Checkpoint(optimizer=generator_optimizer,\n",
        "                      model=generator_net,\n",
        "                      optimizer_step=global_counter)\n",
        "\n",
        "discriminator_checkpoint_prefix = os.path.join(checkpoint_dir, \"discriminator_checkpoints\", \"discriminator.ckpt\")\n",
        "disc_root = tfe.Checkpoint(optimizer=discriminator_optimizer,\n",
        "                      model=discriminator_net,\n",
        "                      optimizer_step=global_counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wbjnfUSI-Mf4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalizer(image, label):\n",
        "  # image = tf.image.resize_images(image, (48,48))\n",
        "  image = 2 * tf.to_float(image) / 255.0 - 1.0\n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QP-ddzH_1zNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = np.zeros((X_train.shape[0]))\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.map(normalizer)\n",
        "train_dataset = train_dataset.shuffle(1000)\n",
        "train_dataset = train_dataset.repeat()\n",
        "train_dataset = train_dataset.batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BzLwoZUWelPL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_images(dataset, denomalize=True):\n",
        "    fig, axes = plt.subplots(6, 6, sharex=True, sharey=True)\n",
        "    for ii, ax in enumerate(axes.flatten()):\n",
        "        img = dataset[ii,:,:,:]\n",
        "        if denomalize:\n",
        "            img = ((img + 1)*255 / 2).astype(np.uint8) # Scale back to 0-255\n",
        "        ax.imshow(img, aspect='equal')\n",
        "      \n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.yaxis.set_visible(False)\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LhyhBwto2Sut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# generate sample noise for evaluation\n",
        "fake_input_test = tf.random_uniform(shape=(36, z_size),\n",
        "                                 minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "epoch = 0\n",
        "for counter, (batch_real_images, batch_real_labels) in enumerate(train_dataset):\n",
        "  fake_input = tf.random_uniform(shape=(batch_size, z_size),\n",
        "                                 minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "  \n",
        "  batch_real_images = tf.to_float(batch_real_images)\n",
        "  with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
        "    \n",
        "    # run the generator with the random noise batch\n",
        "    g_model = generator_net(fake_input, is_training=True)\n",
        "    #print(g_model.shape)\n",
        "    # run the discriminator with real input images\n",
        "    d_logits_real = discriminator_net(batch_real_images, is_training=True)\n",
        "      \n",
        "    # run the discriminator with fake input images (images from the generator)\n",
        "    d_logits_fake = discriminator_net(g_model, is_training=True)\n",
        "    \n",
        "    # compute the generator loss\n",
        "    gen_loss = generator_loss(d_logits_fake)\n",
        "    \n",
        "    # compute the discriminator loss\n",
        "    dis_loss = discriminator_loss(d_logits_real, d_logits_fake)\n",
        "    \n",
        "    #print(\"Generator loss:\", gen_loss, \"Discriminator loss:\", dis_loss)\n",
        "   \n",
        "  discriminator_grads = d_tape.gradient(dis_loss, discriminator_net.variables)\n",
        "  generator_grads = g_tape.gradient(gen_loss, generator_net.variables)\n",
        "  \n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator_net.variables), global_step=global_counter)\n",
        "  generator_optimizer.apply_gradients(zip(generator_grads, generator_net.variables), global_step=global_counter)\n",
        "  \n",
        "  counter += 1\n",
        "    \n",
        "  if counter % 50 == 0:\n",
        "    if counter % 1000 == 0:\n",
        "    \n",
        "        # save generator and discriminator checkpoints\n",
        "        gen_root.save(file_prefix=generator_checkpoint_prefix)\n",
        "        disc_root.save(file_prefix=discriminator_checkpoint_prefix)\n",
        "\n",
        "        generated_samples = generator_net(fake_input_test, is_training=False)\n",
        "        display_images(generated_samples.numpy())\n",
        "        \n",
        "    epoch += 1\n",
        "    print(\"Epoch:\", epoch) \n",
        "    \n",
        "  if epoch == 250:\n",
        "    generated_samples = generator_net(fake_input_test, is_training=False)\n",
        "    display_images(generated_samples.numpy())\n",
        "    break\n",
        "\n",
        "  gen_root.save(file_prefix=generator_checkpoint_prefix)\n",
        "  disc_root.save(file_prefix=discriminator_checkpoint_prefix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c8ebZ1kxhQfg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}