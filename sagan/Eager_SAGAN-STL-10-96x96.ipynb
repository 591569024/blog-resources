{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/sthalles/blog-resources/blob/master/sagan/Eager_SAGAN-STL-10.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Daz4EN2qNu27",
    "outputId": "6916e181-70c3-447c-d9c5-cdbbf52fb460"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from stl10_input import read_all_images\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_all_images(\"./data/stl10_binary/train_X.bin\")\n",
    "print(\"Train data shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "id": "2paiYCUGODZQ",
    "outputId": "0113b670-2ffa-405e-e565-42ff5a67a3ef"
   },
   "outputs": [],
   "source": [
    "cifar_10 = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "n_classes = len(cifar_10)\n",
    "print(\"Number of classes:\", n_classes)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(18,8))\n",
    "n_columns = 8\n",
    "n_rows = 4\n",
    "\n",
    "for i in range(1,n_columns*n_rows+1):\n",
    "  fig.add_subplot(n_rows, n_columns, i)\n",
    "  plt.imshow(X_train[i])\n",
    "  # plt.title(cifar_10[y_train[i]])\n",
    "  # Turn off tick labels\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "ymSP1wKj9N0E",
    "outputId": "4fd5c713-c0d8-43d4-be26-dbff783f66be"
   },
   "outputs": [],
   "source": [
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "AepL7NbSdcFi",
    "outputId": "a5630c93-a7de-45ce-e8e1-b5655f177e1e"
   },
   "outputs": [],
   "source": [
    "# # simulate conv filter\n",
    "# w = tfe.Variable(tf.truncated_normal(shape=[3, 3, 16, 32])) # (3, 3, 16, 32)\n",
    "# print(\"w:\", w.shape)\n",
    "\n",
    "# u = tfe.Variable(tf.truncated_normal(shape=[1,w.shape[-1]])) # (1, 32)\n",
    "# print(\"u:\", u.shape)\n",
    "\n",
    "# w_reshape = tf.reshape(w, (-1, w.shape[-1])) # (144, 32)\n",
    "# print(\"w_reshape:\", w_reshape.shape)\n",
    "\n",
    "# wu = tf.matmul(u, tf.transpose(w_reshape)) # (1, 144)\n",
    "# print(\"wu:\", wu.shape)\n",
    "# v = wu / tf.nn.l2_normalize(wu)\n",
    "# print(\"v:\", v.shape)\n",
    "\n",
    "# wv = tf.matmul(v, w_reshape)\n",
    "# u = wv / tf.nn.l2_normalize(wv)\n",
    "# print(\"u:\", u.shape)\n",
    "\n",
    "# # Calculate WSN with the spectral norm\n",
    "# sigma = tf.matmul(tf.matmul(v, w_reshape), tf.transpose(u))\n",
    "# WSN = w_reshape / sigma\n",
    "# print(\"WSN:\", WSN.shape)\n",
    "\n",
    "# WSN = tf.reshape(WSN, w.shape)\n",
    "# print(\"WSN:\", WSN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "8Ck_G_m7XczB",
    "outputId": "b59e66a2-2a41-4e55-9b5a-f2a872c683ad"
   },
   "outputs": [],
   "source": [
    "class SelfAttention(tf.keras.Model):\n",
    "  def __init__(self, number_of_filters):\n",
    "    super(SelfAttention, self).__init__(number_of_filters)\n",
    "    \n",
    "    self.f = tf.keras.layers.Conv2D(number_of_filters//8, 1, \n",
    "                                     strides=1, padding='SAME', \n",
    "                                     activation=None)\n",
    "    \n",
    "    self.g = tf.keras.layers.Conv2D(number_of_filters//8, 1, \n",
    "                                     strides=1, padding='SAME', \n",
    "                                     activation=None)\n",
    "    \n",
    "    self.h = tf.keras.layers.Conv2D(number_of_filters, 1, \n",
    "                                     strides=1, padding='SAME', \n",
    "                                     activation=None)\n",
    "    \n",
    "    self.gamma = tfe.Variable(0.0, trainable=True, dtype=tf.float32) \n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "    \n",
    "  def call(self, x):\n",
    "    input_shape = tf.shape(x)\n",
    "    f = self.f(x)\n",
    "    g = self.g(x)\n",
    "    h = self.h(x)\n",
    "    \n",
    "    f_flatten = self.flatten(f)\n",
    "    g_flatten = self.flatten(g)\n",
    "    h_flatten = self.flatten(h)\n",
    "    \n",
    "    s = tf.matmul(g_flatten, f_flatten, transpose_b=True)\n",
    "    B = tf.nn.softmax(s)\n",
    "\n",
    "    o = tf.matmul(B, h_flatten)\n",
    "    \n",
    "    y = self.gamma * o + self.flatten(x)\n",
    "    return tf.reshape(y, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/sngan_network_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "g52OgUeWYU6T",
    "outputId": "e6a58661-b4d6-42c1-ae33-7991956ca0a0"
   },
   "outputs": [],
   "source": [
    "z_size = 128\n",
    "learning_rate_generator = 0.0001\n",
    "learning_rate_discriminator = 0.0004\n",
    "batch_size = 100\n",
    "alpha = 0.1\n",
    "beta1 = 0.0\n",
    "beta2 = 0.9\n",
    "bn_momentum = 0.1\n",
    "bn_epsilon  = 0.00002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.conv_spectral_norm import Conv2D, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "AuqiX32cONPo",
    "outputId": "cb03379d-5ffe-4720-8775-ccb404067201"
   },
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(Generator, self).__init__()\n",
    "    # define the generator's layers\n",
    "    \n",
    "    self.fc1 = tf.keras.layers.Dense(units=6*6*512, activation=\"relu\")\n",
    "\n",
    "    self.transp_conv1 = Conv2DTranspose(256, 4, spectral_normalization=True, strides=2, padding=\"SAME\", activation=None)\n",
    "    \n",
    "    # BN + ReLU\n",
    "    self.bn1 = tf.keras.layers.BatchNormalization(scale=False, epsilon=bn_epsilon, momentum=bn_momentum)\n",
    "    self.activation1 = tf.keras.layers.Activation(activation='relu')\n",
    "    \n",
    "    self.transp_conv2 = Conv2DTranspose(128, 4, spectral_normalization=True, strides=2, padding=\"SAME\", activation=None)\n",
    "    \n",
    "    # BN + ReLU\n",
    "    self.bn2 = tf.keras.layers.BatchNormalization(scale=False, epsilon=bn_epsilon, momentum=bn_momentum)\n",
    "    self.activation2 = tf.keras.layers.Activation(activation='relu')\n",
    "    \n",
    "    self.transp_conv3 = Conv2DTranspose(64, 4, spectral_normalization=True, strides=2, padding=\"SAME\", activation=None)\n",
    "    \n",
    "    self.bn3 = tf.keras.layers.BatchNormalization(scale=False, epsilon=bn_epsilon, momentum=bn_momentum)\n",
    "    self.activation3 = tf.keras.layers.Activation(activation='relu')\n",
    "    \n",
    "    # pass the number of filters of the current feature volume\n",
    "    self.attention = SelfAttention(64)\n",
    "\n",
    "    self.transp_conv4 = Conv2DTranspose(32, 4, spectral_normalization=True, strides=2, padding=\"SAME\", activation=None)\n",
    "    \n",
    "    self.bn4 = tf.keras.layers.BatchNormalization(scale=False, epsilon=bn_epsilon, momentum=bn_momentum)\n",
    "    self.activation4 = tf.keras.layers.Activation(activation='relu')\n",
    "    \n",
    "    self.conv = Conv2D(3, 3, strides=1, spectral_normalization=True, padding='SAME', activation=None)\n",
    "    self.out = tf.keras.layers.Activation(activation='tanh')\n",
    "    \n",
    "  def call(self, z, is_training):\n",
    "\n",
    "    fc1 = self.fc1(z)\n",
    "    fc1_reshaped = tf.reshape(fc1, (-1,6,6,512))\n",
    "\n",
    "    trans_conv1 = self.transp_conv1(fc1_reshaped, training=is_training)\n",
    "    bn1 = self.bn1(trans_conv1, training=is_training)\n",
    "    activation1 = self.activation1(bn1)\n",
    "\n",
    "    transp_conv2 = self.transp_conv2(activation1, training=is_training)\n",
    "    bn2 = self.bn2(transp_conv2, training=is_training)\n",
    "    activation2 = self.activation2(bn2)\n",
    "    \n",
    "    transp_conv3 = self.transp_conv3(activation2, training=is_training)\n",
    "    bn3 = self.bn3(transp_conv3, training=is_training)\n",
    "    activation3 = self.activation3(bn3)\n",
    "    \n",
    "    attention = self.attention(activation3)\n",
    "    \n",
    "    transp_conv4 = self.transp_conv3(attention, training=is_training)\n",
    "    bn4 = self.bn3(transp_conv4, training=is_training)\n",
    "    activation4 = self.activation3(bn4)\n",
    "    \n",
    "    conv = self.conv(activation4, training=is_training)\n",
    "    output = self.out(conv)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "vhqWL2DTZSPO",
    "outputId": "4ea4f35e-9cd7-486c-c758-f345422b13b2"
   },
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "  def __init__(self, alpha):\n",
    "    super(Discriminator, self).__init__()\n",
    "    \n",
    "    # -------- Block 1\n",
    "    self.conv1 = Conv2D(32, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
    "    self.activation1 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "  \n",
    "    self.conv2 = Conv2D(32, 4, spectral_normalization=True, strides=2, padding='SAME', activation=None)\n",
    "    self.activation2 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    \n",
    "    # pass the number of filters of the current feature volume\n",
    "    self.attention = SelfAttention(32)\n",
    "    \n",
    "    # -------- Block 2\n",
    "    self.conv3 = Conv2D(64, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
    "    self.activation3 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    \n",
    "    self.conv4 = Conv2D(64, 4, spectral_normalization=True, strides=2, padding='SAME', activation=None)\n",
    "    self.activation4 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    \n",
    "    # -------- Block 3\n",
    "    self.conv5 = Conv2D(128, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
    "    self.activation5 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    \n",
    "    self.conv6 = Conv2D(128, 4, spectral_normalization=True, strides=2, padding='SAME', activation=None)\n",
    "    self.activation6 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    \n",
    "    # -------- Block 4\n",
    "    self.conv7 = Conv2D(256, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
    "    self.activation7 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    \n",
    "    self.conv8 = Conv2D(256, 4, spectral_normalization=True, strides=2, padding='SAME', activation=None)\n",
    "    self.activation8 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    # --------\n",
    "    \n",
    "    self.conv9 = Conv2D(512, 3, spectral_normalization=True, strides=1, padding='SAME', activation=None)\n",
    "    self.activation9 = tf.keras.layers.LeakyReLU(alpha=alpha)\n",
    "    \n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "    self.fc1 = tf.keras.layers.Dense(units=1, activation=None)\n",
    "    \n",
    "  \n",
    "  def call(self, inputs, is_training):\n",
    "\n",
    "    conv1 = self.conv1(inputs, training=is_training)\n",
    "    activation1 = self.activation1(conv1)\n",
    "        \n",
    "    conv2 = self.conv2(activation1, training=is_training)\n",
    "    activation2 = self.activation2(conv2)\n",
    "    \n",
    "    attention = self.attention(activation2)\n",
    "\n",
    "    conv3 = self.conv3(attention, training=is_training)\n",
    "    activation3 = self.activation3(conv3)\n",
    "    \n",
    "    conv4 = self.conv4(activation3, training=is_training)\n",
    "    activation4 = self.activation4(conv4)\n",
    "    \n",
    "    conv5 = self.conv5(activation4, training=is_training)\n",
    "    activation5 = self.activation5(conv5)\n",
    "    \n",
    "    conv6 = self.conv6(activation5, training=is_training)\n",
    "    activation6 = self.activation6(conv6)\n",
    "    \n",
    "    conv7 = self.conv7(activation6, training=is_training)\n",
    "    activation7 = self.activation7(conv7)\n",
    "    \n",
    "    conv8 = self.conv8(activation7, training=is_training)\n",
    "    activation8 = self.activation8(conv8)\n",
    "    \n",
    "    conv9 = self.conv9(activation8, training=is_training)\n",
    "    activation9 = self.activation9(conv8)\n",
    "    \n",
    "    flat = self.flatten(activation9)\n",
    "    logits = self.fc1(flat)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "Ehm_VlwuVLGy",
    "outputId": "13b6b750-940c-467b-9894-8f40ad28e8e2"
   },
   "outputs": [],
   "source": [
    "generator_net = Generator()\n",
    "discriminator_net = Discriminator(alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "QveA21KOB4XM",
    "outputId": "48428b36-8042-42a2-82c6-1590dcd86db5"
   },
   "outputs": [],
   "source": [
    "def generator_loss(d_logits_fake):\n",
    "  return - tf.reduce_mean(d_logits_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "1BenLQsgCvnR",
    "outputId": "fa086f1f-4972-49b0-8f09-b5a23141266d"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(d_logits_real, d_logits_fake):\n",
    "  return tf.reduce_mean(- tf.minimum(0, -1. + d_logits_real)) - tf.reduce_mean(tf.minimum(0, -1. - d_logits_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "11WPYNiD1Tdw",
    "outputId": "b67070b2-5938-496a-a36e-88bc264dd076"
   },
   "outputs": [],
   "source": [
    "logdir = \"./model/logs/\"\n",
    "tf_board_writer = tf.contrib.summary.create_file_writer(logdir)\n",
    "tf_board_writer.set_as_default()\n",
    "\n",
    "global_counter = tf.train.get_or_create_global_step()\n",
    "generator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_generator, beta1=beta1, beta2=beta2)\n",
    "discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_discriminator, beta1=beta1, beta2=beta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./model\"\n",
    "generator_checkpoint_prefix = os.path.join(checkpoint_dir, \"generator_checkpoints\", \"generator.ckpt\")\n",
    "gen_root = tfe.Checkpoint(optimizer=generator_optimizer,\n",
    "                      model=generator_net,\n",
    "                      optimizer_step=global_counter)\n",
    "\n",
    "discriminator_checkpoint_prefix = os.path.join(checkpoint_dir, \"discriminator_checkpoints\", \"discriminator.ckpt\")\n",
    "disc_root = tfe.Checkpoint(optimizer=discriminator_optimizer,\n",
    "                      model=discriminator_net,\n",
    "                      optimizer_step=global_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "wbjnfUSI-Mf4",
    "outputId": "35e30c5a-6221-4d85-c668-2931d7b9e781"
   },
   "outputs": [],
   "source": [
    "def normalizer(image, label):\n",
    "  # image = tf.image.resize_images(image, (48,48))\n",
    "  image = 2 * tf.to_float(image) / 255.0 - 1.0\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "QP-ddzH_1zNd",
    "outputId": "9769df2a-9919-4e8e-943f-ff5354508e2d"
   },
   "outputs": [],
   "source": [
    "y_train = np.zeros((X_train.shape[0]))\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.map(normalizer)\n",
    "train_dataset = train_dataset.shuffle(1000)\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "BzLwoZUWelPL",
    "outputId": "bd976d45-9fd9-400d-b909-c3cfde7b8df9"
   },
   "outputs": [],
   "source": [
    "def display_images(dataset, denomalize=True):\n",
    "    fig, axes = plt.subplots(6, 6, sharex=True, sharey=True)\n",
    "    for ii, ax in enumerate(axes.flatten()):\n",
    "        img = dataset[ii,:,:,:]\n",
    "        if denomalize:\n",
    "            img = ((img + 1)*255 / 2).astype(np.uint8) # Scale back to 0-255\n",
    "        ax.imshow(img, aspect='equal')\n",
    "      \n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2713
    },
    "colab_type": "code",
    "id": "LhyhBwto2Sut",
    "outputId": "01cfe536-551a-4407-8f9b-e931c54afca3"
   },
   "outputs": [],
   "source": [
    "# generate sample noise for evaluation\n",
    "fake_input_test = tf.random_uniform(shape=(36, z_size),\n",
    "                                 minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
    "epoch = 0\n",
    "for counter, (batch_real_images, batch_real_labels) in enumerate(train_dataset):\n",
    "  fake_input = tf.random_uniform(shape=(batch_size, z_size),\n",
    "                                 minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
    "  \n",
    "  batch_real_images = tf.to_float(batch_real_images)\n",
    "  with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "    \n",
    "    # run the generator with the random noise batch\n",
    "    g_model = generator_net(fake_input, is_training=True)\n",
    "    #print(g_model.shape)\n",
    "    # run the discriminator with real input images\n",
    "    d_logits_real = discriminator_net(batch_real_images, is_training=True)\n",
    "      \n",
    "    # run the discriminator with fake input images (images from the generator)\n",
    "    d_logits_fake = discriminator_net(g_model, is_training=True)\n",
    "    \n",
    "    # compute the generator loss\n",
    "    gen_loss = generator_loss(d_logits_fake)\n",
    "    \n",
    "    # compute the discriminator loss\n",
    "    dis_loss = discriminator_loss(d_logits_real, d_logits_fake)\n",
    "    \n",
    "    #print(\"Generator loss:\", gen_loss, \"Discriminator loss:\", dis_loss)\n",
    "   \n",
    "  discriminator_grads = d_tape.gradient(dis_loss, discriminator_net.variables)\n",
    "  generator_grads = g_tape.gradient(gen_loss, generator_net.variables)\n",
    "  \n",
    "  discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator_net.variables), global_step=global_counter)\n",
    "  generator_optimizer.apply_gradients(zip(generator_grads, generator_net.variables), global_step=global_counter)\n",
    "  \n",
    "  counter += 1\n",
    "    \n",
    "  if counter % 50 == 0:\n",
    "    if counter % 1000 == 0:\n",
    "    \n",
    "        # save generator and discriminator checkpoints\n",
    "        gen_root.save(file_prefix=generator_checkpoint_prefix)\n",
    "        disc_root.save(file_prefix=discriminator_checkpoint_prefix)\n",
    "\n",
    "        generated_samples = generator_net(fake_input_test, is_training=False)\n",
    "        display_images(generated_samples.numpy())\n",
    "        \n",
    "    epoch += 1\n",
    "    print(\"Epoch:\", epoch) \n",
    "    \n",
    "  if epoch == 250:\n",
    "    generated_samples = generator_net(fake_input_test, is_training=False)\n",
    "    display_images(generated_samples.numpy())\n",
    "    break\n",
    "\n",
    "  gen_root.save(file_prefix=generator_checkpoint_prefix)\n",
    "  disc_root.save(file_prefix=discriminator_checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8ebZ1kxhQfg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Generative_Adversarial_Nets_Eager.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
